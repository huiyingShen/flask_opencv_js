<!DOCTYPE html>
<head>
  
<style>
canvas {
    border: 1px solid black;
}
video {
    border: 1px solid black;
}
.err {
    color: red;
}
</style>
</head>
<body>
<link href="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.css" rel="stylesheet">
<script src="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>

<p class="err" id="vdErr"></p>
</div>
<div id="contentarea">
    <button id="startup" disabled="true" onclick="startup()">start</button>
    <button id="stop"  onclick="stopCamera()">stop</button><br>
    <video id="video" style="display:none;" > </video>
    <canvas id="canvasOutput"></canvas>
    <canvas id="map_canvas"></canvas>
</div>
<script
async src="{{ url_for('static', filename='opencv.js') }}" id="opencvjs">
// async src="https://huiyingshen.github.io/flask_opencv_js/static/opencv.js" id="opencvjs"  crossorigin="anonymous">
</script>

<script >

const map_canvas = document.getElementById('map_canvas');
const map_ctx = map_canvas.getContext('2d');
const map_img = new Image();

map_img.src = 'https://huiyingshen.github.io/flask_opencv_js/market_tmap.png';
map_img.crossOrigin = "Anonymous";

map_img.onload = function() {
    map_canvas.width = map_img.width;
    map_canvas.height = map_img.height;
    map_ctx.drawImage(map_img, 0, 0, map_canvas.width, map_canvas.height); // Drawing the image on the canvas at position (0,0) and scaling it to fill the canvas
};


let width = 640;
let height = 480;

let gestureRecognizer;
let createGestureRecognizer;
let runningMode = "IMAGE";
let enableWebcamButton;
let webcamRunning = false;

const videoHeight = height.toString() + "px";
const videoWidth = width.toString() + "px";
// Before we can use HandLandmarker class we must wait for it to finish
// loading. Machine Learning models can be large and take a moment to
// get everything needed to run.

const video1 = document.getElementById("video");
const canvasElement = document.getElementById("canvasOutput");
const canvasCtx = canvasElement.getContext("2d");

let lastVideoTime = -1;
let results = undefined;
async function predictWebcam() {
    const webcamElement = document.getElementById("video");
    // Now let's start detecting the stream.
    if (runningMode === "IMAGE") {
        runningMode = "VIDEO";
        await gestureRecognizer.setOptions({ runningMode: "VIDEO" });
    }
    let nowInMs = Date.now();
    if (video1.currentTime !== lastVideoTime) {
        lastVideoTime = video1.currentTime;
        results = gestureRecognizer.recognizeForVideo(video1, nowInMs);
    }
    canvasCtx.save();
    // canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
    canvasElement.style.height = videoHeight;
    webcamElement.style.height = videoHeight;
    canvasElement.style.width = videoWidth;
    webcamElement.style.width = videoWidth;
    if (results.landmarks) {
        for (const landmarks of results.landmarks) {
            drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, {
                color: "#00FF00",
                lineWidth: 3
            });
            drawLandmarks(canvasCtx, landmarks, { color: "#FF0000", lineWidth: 1 });
            canvasCtx.beginPath();
            x = landmarks[8]["x"]*width;
            y = landmarks[8]["y"]*height;
            canvasCtx.ellipse(x, y, 10, 10, Math.PI / 4, 0, 2 * Math.PI);
            canvasCtx.stroke();
        }
    }
    // canvasCtx.restore();
}

// In this case, We set width 320, and the height will be computed based on the input stream.


// whether streaming video from the camera.
let streaming = false;

// Some HTML elements we need to configure.
let video = null;
let start = null;
let stream = null;

let loopIndex = 0;

let cap = null;
let inputImage = null;
let markerImage = null;
let dictionary = null;
let parameter = null;
let markerIds = null;
let markerCorners = null;
let RgbImage = null;

function get_aruco(){

    loopIndex = setInterval(one_time_step,100);
}



function one_time_step(){
    cap.read(inputImage);
    detect_show_aruco(inputImage,"canvasOutput")
    predictWebcam();
}

function detect_show_aruco(img,canvas_name){
    if (img === null) return;
    cv.cvtColor(img, RgbImage, cv.COLOR_RGBA2RGB, 0);
    cv.detectMarkers(RgbImage, dictionary, markerCorners, markerIds);
    if (markerIds.rows > 0) {
        cv.drawDetectedMarkers(RgbImage, markerCorners, markerIds);
    }
    cv.imshow(canvas_name, RgbImage);
}

function initVideo(ev){
    if (!streaming) {
        height = video.videoHeight / (video.videoWidth/width);
        video.setAttribute("width", width);
        video.setAttribute("height", height);
        streaming = true;
    }
    playVideo();
}

function startup() {
    video = document.getElementById("video");
    start = document.getElementById("startup");

    navigator.mediaDevices.getUserMedia({ video: {facingMode: "environment"}, audio: false })
        .then(function(s) {
            stream = s;
            video.srcObject = stream;
            video.play();
        })
        .catch(function(err) {
            console.log("An error occured! " + err);
    });

    video.addEventListener("canplay", initVideo, false);
}
function stopCamera() {
    clearInterval(loopIndex);
    if (inputImage != null && !inputImage.isDeleted()) {
        inputImage.delete();
        inputImage = null;
    }
    if (markerImage != null && !markerImage.isDeleted()) {
        markerImage.delete();
        markerImage = null;
    }
    if (dictionary != null && !dictionary.isDeleted()) {
        dictionary.delete();
        dictionary = null;
    }
    
    if (markerIds != null && !markerIds.isDeleted()) {
        markerIds.delete();
        markerIds = null;
    }
    if (markerCorners != null && !markerCorners.isDeleted()) {
        markerCorners.delete();
        markerCorners = null;
    }
    
    if (RgbImage != null && !RgbImage.isDeleted()) {
        RgbImage.delete();
        RgbImage = null;
    }
    
    document.getElementById("canvasOutput").getContext("2d").clearRect(0, 0, width, height);
    video.pause();
    video.srcObject = null;
    stream.getVideoTracks()[0].stop();
    start.disabled = false;
    video.removeEventListener("canplay", initVideo);
}

function playVideo() {
    if (!streaming) {
        console.warn("Please startup your webcam");
        return;
    }
    try {

        markerImage = new cv.Mat();
        dictionary = new cv.aruco_Dictionary(cv.DICT_4X4_250);

        markerIds = new cv.Mat();
        markerCorners  = new cv.MatVector();
        RgbImage = new cv.Mat();
        cap = new cv.VideoCapture("video");

        let img = cv.imread("map_canvas");
        detect_show_aruco(img,"map_canvas")
        img.delete();

        inputImage = new cv.Mat(height, width, cv.CV_8UC4);

        get_aruco();
        document.getElementById("vdErr").innerHTML = " ";
    } catch(err) {
        document.getElementById("vdErr").innerHTML = err;
    }
    start.disabled = true;
}

function onReady() {
    document.getElementById("startup").disabled = false;
    console.log("opencvjs is loaded!");

}
if (typeof cv !== 'undefined') {
    onReady();
} else {
    document.getElementById("opencvjs").onload = onReady;
}
</script>

<script id="rendered-js" type="module">
  import { GestureRecognizer, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";
  const createGestureRecognizer = async () => {
        const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm");
        gestureRecognizer = await GestureRecognizer.createFromOptions(vision, {
            baseOptions: {
                modelAssetPath: "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task",
                delegate: "GPU"
            },
            runningMode: runningMode
        });
    };
    createGestureRecognizer();

    window.gestureRecognizer = gestureRecognizer;
    window.runningMode = runningMode;
</script>


</body>
