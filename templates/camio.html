<!DOCTYPE html>
<head>
  
<style>
canvas {
    border: 1px solid black;
}
video {
    border: 1px solid black;
}
.err {
    color: red;
}
</style>
</head>
<body>
<link href="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.css" rel="stylesheet">
<script src="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>

<script id="rendered-js" type="module">
  import { GestureRecognizer, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";
  window.GestureRecognizer = GestureRecognizer;
  window.FilesetResolver = FilesetResolver;
</script>


<p class="err" id="vdErr"></p>
</div>
<div id="contentarea">
    <button id="startup" disabled="true" onclick="startup()">start</button><br>
    <video id="video">Your browser does not support the video tag.</video>
    <canvas id="canvasOutput"></canvas>
</div>

<script async src="{{ url_for('static', filename='opencv.js') }}" id="opencvjs"></script>

<script >

let gestureRecognizer;
let runningMode = "IMAGE";
let enableWebcamButton;
let webcamRunning = false;
const videoHeight = "360px";
const videoWidth = "480px";
// Before we can use HandLandmarker class we must wait for it to finish
// loading. Machine Learning models can be large and take a moment to
// get everything needed to run.
const createGestureRecognizer = async () => {
    const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm");
    gestureRecognizer = await GestureRecognizer.createFromOptions(vision, {
        baseOptions: {
            modelAssetPath: "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task",
            delegate: "GPU"
        },
        runningMode: runningMode
    });
    demosSection.classList.remove("invisible");
};
createGestureRecognizer();

// In this case, We set width 320, and the height will be computed based on the input stream.
let width = 640;
let height = 0;

// whether streaming video from the camera.
let streaming = false;

// Some HTML elements we need to configure.
let video = null;
let start = null;
let stream = null;

let loopIndex = 0;

let cap = null;
let inputImage = null;
let markerImage = null;
let dictionary = null;
let parameter = null;
let markerIds = null;
let markerCorners = null;
let RgbImage = null;

function get_aruco(){
    inputImage = new cv.Mat(height, width, cv.CV_8UC4);
    markerImage = new cv.Mat();
    dictionary = new cv.aruco_Dictionary(cv.DICT_4X4_250);

    markerIds = new cv.Mat();
    markerCorners  = new cv.MatVector();
    RgbImage = new cv.Mat();
    cap = new cv.VideoCapture("video");
    loopIndex = setInterval(
        // function(){
        //     cap.read(inputImage);
        //     cv.cvtColor(inputImage, RgbImage, cv.COLOR_RGBA2RGB, 0);
        //     cv.detectMarkers(RgbImage, dictionary, markerCorners, markerIds);
        //     if (markerIds.rows > 0) {
        //         cv.drawDetectedMarkers(RgbImage, markerCorners, markerIds);
        //     }
        //     cv.imshow("canvasOutput", RgbImage);
        // }
        one_time_step
        , 33);
}

function one_time_step(){
    cap.read(inputImage);
    cv.cvtColor(inputImage, RgbImage, cv.COLOR_RGBA2RGB, 0);
    cv.detectMarkers(RgbImage, dictionary, markerCorners, markerIds);
    if (markerIds.rows > 0) {
        cv.drawDetectedMarkers(RgbImage, markerCorners, markerIds);
    }
    cv.imshow("canvasOutput", RgbImage);
}

function initVideo(ev){
    if (!streaming) {
        height = video.videoHeight / (video.videoWidth/width);
        video.setAttribute("width", width);
        video.setAttribute("height", height);
        streaming = true;
    }
    playVideo();
}

function startup() {
    video = document.getElementById("video");
    start = document.getElementById("startup");

    navigator.mediaDevices.getUserMedia({ video: {facingMode: "environment"}, audio: false })
        .then(function(s) {
            stream = s;
            video.srcObject = stream;
            video.play();
        })
        .catch(function(err) {
            console.log("An error occured! " + err);
    });

    video.addEventListener("canplay", initVideo, false);
}

function playVideo() {
    if (!streaming) {
        console.warn("Please startup your webcam");
        return;
    }
    try {
        get_aruco();
        document.getElementById("vdErr").innerHTML = " ";
    } catch(err) {
        document.getElementById("vdErr").innerHTML = err;
    }
    start.disabled = true;
}

function onReady() {
    document.getElementById("startup").disabled = false;
}
if (typeof cv !== 'undefined') {
    onReady();
} else {
    document.getElementById("opencvjs").onload = onReady;
}
</script>


</body>